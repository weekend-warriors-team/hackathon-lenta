Важно: модель разработана с использованием библиотеки pandas версии 1.5.3.

**Цель:**

Разработка модели, прогнозирующей спрос на 14 дней для товаров собственного
производства. Гранулярность ТК-SKU-День.
_____

Построить модель прогноза спроса на основе **мастер данных** и данных продаж с учетом разных
признаков.
_____
**Задачи:**

- Сгенерировать различные интерпретируемые признаки.
- Необходимо сделать подневной прогноз спроса на тестовом периоде для каждого товара и магазина, и команда Ленты оценит его качество в сравнении с свершившимся фактом.
_____
**Метрика:**
Метрикой качества - WAPE, посчитанный на уровне товар, магазин, день.
Если есть пропущенные значения и по каким-то товарам не предоставлен прогноз, прогноз считается равным нулю.
_____
**Результат:**

Результат содержит:
1. Файл в зафиксированном формате с результатом прогноза спроса(sales_submission.csv).
2. Воспроизводимый код на Python
3. Описание решения:
a. Описание модели прогноза спроса, которую вы зафитили
i. Признаки
ii. интерпретация (shapley values),
iii. кросс-валидация
iv. алгоритмы
b. Описание вашего алгоритма оптимизации:
i. методология расчетов
ii. скорость оптимизации

Критерии оценки:
У вас есть тестовый датасет за более поздние периоды в рамках групп товаров собственного производства. Ваш алгоритм должен показать высокую точность прогнозирования спроса с использованием признаков, которые вы сочтёте нужными.
Критерии оценки – WAPE + алгоритм прогноза спроса является понятным, эффективным и масштабируемым.
**Анализ данных.**
1) Пропусков в данных нет.
2) В обучающих данных всего 12 магазинов, 1991 товар. Есть тип данных float, который содержит целочисленные значения - столбцы приведены к типу данных 'int'. Столбец date приведён к формату datetime.
3) В данных о товарах содержится информация о 2050 товарах, групп -  9, категорий - 43, субкатегорий - 170, 2 метки: развес или по штучно.
4) В данных о магазинах есть информация о двух закрывшихся магазинах, их также нет в данных результата. Доля информации о закрытых магазинах в обучающих данных менее 0,08%.
5) столбцы с promo дублируют информацию с обычных столбцов продаж, если промо было в этот день, если не было - 0. Решено использовать только столбцы без указания промо, но оставить столбец с флагом - было ли промо в этот день.
6)  в один день в одном магазине на один товар могут быть продажи с акцией и без.
7) не все товары, имеющиеся в таблице pr_df есть в обучающих данных:sales_df_train. Некоторые товары есть в sales_submission, но их нет в sales_df_train.
**Предобработка данных.**
Анализ показал, что данные не имеют нормальное распределение. Следовательно правило трех сигм к данным не применимо, никакие выбросы не были удалены.
1. Видны выбросы в обучающем наборе данных о закрытых магазинах (0,08%).
2. Были удалены строки с отрицательными или нулевыми продажами (7.5%).
3. Были удалены столбцы, содержащие информацию о промо (так как она дублируется в столбцах продажа в рублях/ штуках).
4. Видны выбросы в продажах в рублях (1,36%).
5. Видны выбросы в units (1,73%).
6. Дубликатов не обнаружено.
**EDA.**
Числовые признаки:
1. Добавлен признак price: продажи/количество проданных товаров.
3. Также добавлен признак: ln(price).
4. Высокая корреляция у pr_sales_in_rub и таргета (что логично, если много потратили, наверное много купили).
5. price_units и sales_union_log имеют отрицательную корреляцию (рост цены - падение спроса).
6. Данные не имеют нормального распределения.
Категориальные данные:
1. Из данных о магазинах сгруппировали объекты по магазину, городу и дивизиону - выделили 6 классов.
2. Сгруппировали данные по группе товаров - получили 6 классов.
**Формирование новых признаков.**
1. Сформированные признаки даты: год, месяц, день продажи, отметка - был ли в этот день праздник.
2. Топ продаваемых товаров -  разделили данные на категории:
    - Ликвидные: покупались каждый день
    - Неликвидные: менее 50 дней
    - Оставшиеся.
Количество категорий выбрано на  основе графических данных.
3. Оборачиваемость магазина:
    - Магазины, продавшие за исследуемый промежуток более 400000 единиц товара.
    - Магазины, продавшие за исследуемый промежуток более 100000 единиц товара.
    - Оставшиеся.
Количество категорий выбрано на  основе графических данных.
4. Кластеризация товаров с помощью метода kmeans. Удалось достичь метрик кластеризации: индекс Дэвиса-Булдина 0.28,  коэффициент силуэта 0.45 и выделить  800 кластеров. 
5. Кластеризация магазинов с помощью метода kmeans. Удалось достичь метрик кластеризации: индекс Дэвиса-Булдина 0.5, коэффициент силуэта 0,38 и выделить  6 кластеров.
**Анализ получившихся признаков и их влияние на качество модели.**
Проанализировав, получившиеся метрки на разном количестве признаков с помощью модели lgbm и важности признаков, получили:
- разработанные признаки не повышали качество модели.
- необходима кластеризация по временным рядам.
**Кластеризация временных рядов.**
- Временные ряды, получали в срезе товар-магазин. В данном случае учитывались только данные без акций.
- Методом kmean кластеризовали ряды, получили значение метрики силуэта 0.65 и выделили 8 кластеров.
- На основе кластера сформировали доп. признаки: сдвиг ( от 1 до 28 дней) и скользящее среднее на 28 дней.
- На основе кластера выделили тренд и сезонность.
**Формирование тестовых и обучающих наборов данных.**
Разработали функции для подготовки признаков данных: отдельно для обучающих и тестовых данных.
**Обучение моделей: выбор типа модели.**
В ввиду ограниченности по времени, было исследовано всего два типа модели:
кэтбуст и lgbm.
Лучший результат и скорость работы показала модель lgbm, в дальнейшем этот тип модели и обучали для каждого дня.
Полученый в ходе кросс-валидации (5 блоков) wape для каждой модели 0.404(5)
Также было принято решение для каждого дня предсказания обучать отдельную модель, настраивая параметры таким образом, чтобы каждая модель могла обобщать имеющиеся данные на 1,2 ... дня вперед. Для реализации этой возможности для каждого нового дня модель обучалась на меньшем количестве столбцов сдвига.
- 1 день: lag_1.....lag_28
- 2 день: lag_2....lag_28 (так как информации о предыдущем дне нет).
- ...
- 14 день: lag_14...lag_28.
Также была рассмотрена модель prophet, она давала хороший скор, но для предсказания в разрезе магазин-товар или кластер. Использование этой модели позволило бы повысить метрику, но необходимость предсказывать на 14 дней вперед потребовало как минимум обучение и настройку 14*8 моделей (на каждый день в разрезе кластера). Временные ресурсы и доступные мощности не позволили нам сделать это.
**Получение итогового предсказания модели.**
Подготовлено 2 функции:
1. Обучение 14 моделей по имеющимся данным.
2. Генерация предсказаний и запись их в таблицу.
**Возможности для масштабирования:**
- функции построены таким образом, что при каждом формировании фич обучающего набора проводится новая кластеризация с учетом новой информации, количество получаемых кластеров можно менять.
- при получении итогового предсказания модели обучаются заново, что позволяет каждый раз подавать новый датасет с новыми данными.
**Точки роста:**
- протестировать большее количество моделей разного типа.
- для каждого дня попробовать обучать модели разного типа и выбрать лучшую.
- организовать лучший тип кросс-валидации с учетом времени.
- кластеризовать временные ряды не только по изменению количества проданных товаров, но и по цене товаров (динамика цены) и по объему продаж. Возможно
это бы дало дополнительную информацию.
- внедрить модели для прогнозирования временных рядов, оценить изменение метрики.
- добавить фичи из библиотеки tsfresh.

